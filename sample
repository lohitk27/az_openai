Model Name	Purpose	Best For	Supported Files
prebuilt-read	OCR	Extracting plain text	PDF, PNG, JPEG, TIFF, BMP
prebuilt-layout	Extract text, tables, headers, footers	Scanned documents, forms	PDF, PNG, JPEG, TIFF, BMP
prebuilt-document	Full document processing (OCR + tables + key-values)	General documents	PDF, PNG, JPEG, TIFF, BMP
prebuilt-receipt	Extracts receipt data (merchant, total, tax, date, items)	Bills, invoices, receipts	PDF, PNG, JPEG, TIFF, BMP
prebuilt-invoice:analyze	Extracts invoice number, date, amounts, vendor details, tax, line items	Invoices (PDF, JPG, PNG, TIFF, DOCX)
prebuilt-businessCard:analyze	Extracts name, company, email, phone, address from business cards	Business cards (PDF, JPG, PNG, TIFF)
prebuilt-document:analyze	Extracts text, tables, key-value pairs, structure	General documents (PDF, DOCX, Images)


from azure.ai.generative.openai import ChatClient
from azure.core.credentials import AzureKeyCredential

# Azure OpenAI Configurations
AZURE_OPENAI_ENDPOINT = "https://YOUR_AZURE_OPENAI_ENDPOINT.openai.azure.com"
API_KEY = "YOUR_API_KEY"
DEPLOYMENT_NAME = "gpt-4o-mini"  # Your deployed model name
API_VERSION = "2024-02-01"  # Azure OpenAI API version

# Initialize the Chat Client
client = ChatClient(endpoint=AZURE_OPENAI_ENDPOINT, credential=AzureKeyCredential(API_KEY))

# Send a chat request
response = client.complete(
    deployment=DEPLOYMENT_NAME,
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "What is the capital of France?"}
    ],
    max_tokens=100
)

# Print the response
print(response.choices[0].message.content)

I have created detailed documentation covering all the necessary steps to access and use our Azure OpenAI models seamlessly. The document includes:

✔️ Step-by-step setup for Python installation and .pem file configuration.
✔️ Instructions on accessing and using deployed models with Azure OpenAI’s ChatCompletion method.
✔️ API call guidelines with deployment names and model details.
✔️ Various methods and example scripts to help you integrate models easily.


import os
from openai import AzureOpenAI

# Set up your Azure OpenAI API key and endpoint
api_key = os.getenv("AZURE_OPENAI_API_KEY")  # Fetch from environment variable
endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")  # Fetch from environment variable
deployment_name = "gpt-4-mini"  # Replace with your deployment name

# Initialize the Azure OpenAI client
client = AzureOpenAI(
    api_key=api_key,
    api_version="2023-05-15",  # Use the latest API version
    azure_endpoint=endpoint,
)

# Function to interact with the GPT-4 model
def chat_with_gpt4(prompt):
    response = client.chat.completions.create(
        model=deployment_name,
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt},
        ],
        max_tokens=150,
        temperature=0.7,
    )
    return response.choices[0].message.content

# Example usage
if __name__ == "__main__":
    user_prompt = "Hello, how can I use Azure OpenAI?"
    response = chat_with_gpt4(user_prompt)
    print("GPT-4 Response:", response)
